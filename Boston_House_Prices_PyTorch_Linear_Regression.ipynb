{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boston-House-Prices-PyTorch-Linear-Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPLWlTs/OV4ZzUXlFuZfSgv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandababugudipudi/Boston-House-Prices-PyTorch-Linear-Regression/blob/main/Boston_House_Prices_PyTorch_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVhBZSTqOqcC"
      },
      "source": [
        "#**Boston House Prices Prediction using Linear Regression using PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVxbE2uYPTE-"
      },
      "source": [
        "###**Linear Regression** \n",
        "Linear Regression is a predictive modeling technique that finds a relationship between independent variable(s) and dependent variable(s). The independent variable(iv)’s can be categorical or continuous, while dependent variable(dv)s are continuous. Underlying function mapping iv’s and dv’s can be linear, quadratic, polynomial or other non-linear functions(like sigmoid function in logistic regression).\n",
        "\n",
        "> Regression techniques are heavily used in making real estate price prediction, financial forecasting, predicting traffic arrival time (ETA)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s845dTvkQSuM"
      },
      "source": [
        "###**Importing the necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhc6wnpHQf7v"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch \n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqSwmcFvQgYt"
      },
      "source": [
        "###**Importing the Dataset**\n",
        "The Boston House prices dataset consists of 506 samples with 13 features with prices ranging from 5.0 to 50.0. Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. The attributes are deﬁned as follows (taken from the UCI Machine Learning Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsLSVAD7Q79R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0ed0f339-4e6b-4f53-9268-cf8e65642356"
      },
      "source": [
        "col_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "# Reading the csv file into numpy array\n",
        "data = pd.read_csv('./boston-house-prices.csv', header = None, delimiter = r\"\\s+\", names = col_names)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n",
              "0  0.00632  18.0   2.31     0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n",
              "1  0.02731   0.0   7.07     0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n",
              "2  0.02729   0.0   7.07     0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n",
              "3  0.03237   0.0   2.18     0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n",
              "4  0.06905   0.0   2.18     0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HTwrf29SVib",
        "outputId": "b56b2a7f-410a-42d8-a667-f283cd6acfa8"
      },
      "source": [
        "# Separating the features and labels in the dataset\n",
        "features = data.drop('MEDV', axis = 1)\n",
        "labels = data['MEDV']\n",
        "print(features)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
            "0    0.00632  18.0   2.31     0  0.538  ...    1  296.0     15.3  396.90   4.98\n",
            "1    0.02731   0.0   7.07     0  0.469  ...    2  242.0     17.8  396.90   9.14\n",
            "2    0.02729   0.0   7.07     0  0.469  ...    2  242.0     17.8  392.83   4.03\n",
            "3    0.03237   0.0   2.18     0  0.458  ...    3  222.0     18.7  394.63   2.94\n",
            "4    0.06905   0.0   2.18     0  0.458  ...    3  222.0     18.7  396.90   5.33\n",
            "..       ...   ...    ...   ...    ...  ...  ...    ...      ...     ...    ...\n",
            "501  0.06263   0.0  11.93     0  0.573  ...    1  273.0     21.0  391.99   9.67\n",
            "502  0.04527   0.0  11.93     0  0.573  ...    1  273.0     21.0  396.90   9.08\n",
            "503  0.06076   0.0  11.93     0  0.573  ...    1  273.0     21.0  396.90   5.64\n",
            "504  0.10959   0.0  11.93     0  0.573  ...    1  273.0     21.0  393.45   6.48\n",
            "505  0.04741   0.0  11.93     0  0.573  ...    1  273.0     21.0  396.90   7.88\n",
            "\n",
            "[506 rows x 13 columns]\n",
            "0      24.0\n",
            "1      21.6\n",
            "2      34.7\n",
            "3      33.4\n",
            "4      36.2\n",
            "       ... \n",
            "501    22.4\n",
            "502    20.6\n",
            "503    23.9\n",
            "504    22.0\n",
            "505    11.9\n",
            "Name: MEDV, Length: 506, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTjMkHMsS2iq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57519d26-94b4-4615-c27c-c613a6fe0168"
      },
      "source": [
        "# Converting the pandas dataframes into PyTorch Tensors\n",
        "# From here onwards our features are inputs and labels are targets\n",
        "inputs = torch.tensor(features.values).float()\n",
        "targets = torch.tensor(labels.values).float()\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00,  ..., 1.5300e+01, 3.9690e+02,\n",
            "         4.9800e+00],\n",
            "        [2.7310e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9690e+02,\n",
            "         9.1400e+00],\n",
            "        [2.7290e-02, 0.0000e+00, 7.0700e+00,  ..., 1.7800e+01, 3.9283e+02,\n",
            "         4.0300e+00],\n",
            "        ...,\n",
            "        [6.0760e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
            "         5.6400e+00],\n",
            "        [1.0959e-01, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9345e+02,\n",
            "         6.4800e+00],\n",
            "        [4.7410e-02, 0.0000e+00, 1.1930e+01,  ..., 2.1000e+01, 3.9690e+02,\n",
            "         7.8800e+00]])\n",
            "tensor([24.0000, 21.6000, 34.7000, 33.4000, 36.2000, 28.7000, 22.9000, 27.1000,\n",
            "        16.5000, 18.9000, 15.0000, 18.9000, 21.7000, 20.4000, 18.2000, 19.9000,\n",
            "        23.1000, 17.5000, 20.2000, 18.2000, 13.6000, 19.6000, 15.2000, 14.5000,\n",
            "        15.6000, 13.9000, 16.6000, 14.8000, 18.4000, 21.0000, 12.7000, 14.5000,\n",
            "        13.2000, 13.1000, 13.5000, 18.9000, 20.0000, 21.0000, 24.7000, 30.8000,\n",
            "        34.9000, 26.6000, 25.3000, 24.7000, 21.2000, 19.3000, 20.0000, 16.6000,\n",
            "        14.4000, 19.4000, 19.7000, 20.5000, 25.0000, 23.4000, 18.9000, 35.4000,\n",
            "        24.7000, 31.6000, 23.3000, 19.6000, 18.7000, 16.0000, 22.2000, 25.0000,\n",
            "        33.0000, 23.5000, 19.4000, 22.0000, 17.4000, 20.9000, 24.2000, 21.7000,\n",
            "        22.8000, 23.4000, 24.1000, 21.4000, 20.0000, 20.8000, 21.2000, 20.3000,\n",
            "        28.0000, 23.9000, 24.8000, 22.9000, 23.9000, 26.6000, 22.5000, 22.2000,\n",
            "        23.6000, 28.7000, 22.6000, 22.0000, 22.9000, 25.0000, 20.6000, 28.4000,\n",
            "        21.4000, 38.7000, 43.8000, 33.2000, 27.5000, 26.5000, 18.6000, 19.3000,\n",
            "        20.1000, 19.5000, 19.5000, 20.4000, 19.8000, 19.4000, 21.7000, 22.8000,\n",
            "        18.8000, 18.7000, 18.5000, 18.3000, 21.2000, 19.2000, 20.4000, 19.3000,\n",
            "        22.0000, 20.3000, 20.5000, 17.3000, 18.8000, 21.4000, 15.7000, 16.2000,\n",
            "        18.0000, 14.3000, 19.2000, 19.6000, 23.0000, 18.4000, 15.6000, 18.1000,\n",
            "        17.4000, 17.1000, 13.3000, 17.8000, 14.0000, 14.4000, 13.4000, 15.6000,\n",
            "        11.8000, 13.8000, 15.6000, 14.6000, 17.8000, 15.4000, 21.5000, 19.6000,\n",
            "        15.3000, 19.4000, 17.0000, 15.6000, 13.1000, 41.3000, 24.3000, 23.3000,\n",
            "        27.0000, 50.0000, 50.0000, 50.0000, 22.7000, 25.0000, 50.0000, 23.8000,\n",
            "        23.8000, 22.3000, 17.4000, 19.1000, 23.1000, 23.6000, 22.6000, 29.4000,\n",
            "        23.2000, 24.6000, 29.9000, 37.2000, 39.8000, 36.2000, 37.9000, 32.5000,\n",
            "        26.4000, 29.6000, 50.0000, 32.0000, 29.8000, 34.9000, 37.0000, 30.5000,\n",
            "        36.4000, 31.1000, 29.1000, 50.0000, 33.3000, 30.3000, 34.6000, 34.9000,\n",
            "        32.9000, 24.1000, 42.3000, 48.5000, 50.0000, 22.6000, 24.4000, 22.5000,\n",
            "        24.4000, 20.0000, 21.7000, 19.3000, 22.4000, 28.1000, 23.7000, 25.0000,\n",
            "        23.3000, 28.7000, 21.5000, 23.0000, 26.7000, 21.7000, 27.5000, 30.1000,\n",
            "        44.8000, 50.0000, 37.6000, 31.6000, 46.7000, 31.5000, 24.3000, 31.7000,\n",
            "        41.7000, 48.3000, 29.0000, 24.0000, 25.1000, 31.5000, 23.7000, 23.3000,\n",
            "        22.0000, 20.1000, 22.2000, 23.7000, 17.6000, 18.5000, 24.3000, 20.5000,\n",
            "        24.5000, 26.2000, 24.4000, 24.8000, 29.6000, 42.8000, 21.9000, 20.9000,\n",
            "        44.0000, 50.0000, 36.0000, 30.1000, 33.8000, 43.1000, 48.8000, 31.0000,\n",
            "        36.5000, 22.8000, 30.7000, 50.0000, 43.5000, 20.7000, 21.1000, 25.2000,\n",
            "        24.4000, 35.2000, 32.4000, 32.0000, 33.2000, 33.1000, 29.1000, 35.1000,\n",
            "        45.4000, 35.4000, 46.0000, 50.0000, 32.2000, 22.0000, 20.1000, 23.2000,\n",
            "        22.3000, 24.8000, 28.5000, 37.3000, 27.9000, 23.9000, 21.7000, 28.6000,\n",
            "        27.1000, 20.3000, 22.5000, 29.0000, 24.8000, 22.0000, 26.4000, 33.1000,\n",
            "        36.1000, 28.4000, 33.4000, 28.2000, 22.8000, 20.3000, 16.1000, 22.1000,\n",
            "        19.4000, 21.6000, 23.8000, 16.2000, 17.8000, 19.8000, 23.1000, 21.0000,\n",
            "        23.8000, 23.1000, 20.4000, 18.5000, 25.0000, 24.6000, 23.0000, 22.2000,\n",
            "        19.3000, 22.6000, 19.8000, 17.1000, 19.4000, 22.2000, 20.7000, 21.1000,\n",
            "        19.5000, 18.5000, 20.6000, 19.0000, 18.7000, 32.7000, 16.5000, 23.9000,\n",
            "        31.2000, 17.5000, 17.2000, 23.1000, 24.5000, 26.6000, 22.9000, 24.1000,\n",
            "        18.6000, 30.1000, 18.2000, 20.6000, 17.8000, 21.7000, 22.7000, 22.6000,\n",
            "        25.0000, 19.9000, 20.8000, 16.8000, 21.9000, 27.5000, 21.9000, 23.1000,\n",
            "        50.0000, 50.0000, 50.0000, 50.0000, 50.0000, 13.8000, 13.8000, 15.0000,\n",
            "        13.9000, 13.3000, 13.1000, 10.2000, 10.4000, 10.9000, 11.3000, 12.3000,\n",
            "         8.8000,  7.2000, 10.5000,  7.4000, 10.2000, 11.5000, 15.1000, 23.2000,\n",
            "         9.7000, 13.8000, 12.7000, 13.1000, 12.5000,  8.5000,  5.0000,  6.3000,\n",
            "         5.6000,  7.2000, 12.1000,  8.3000,  8.5000,  5.0000, 11.9000, 27.9000,\n",
            "        17.2000, 27.5000, 15.0000, 17.2000, 17.9000, 16.3000,  7.0000,  7.2000,\n",
            "         7.5000, 10.4000,  8.8000,  8.4000, 16.7000, 14.2000, 20.8000, 13.4000,\n",
            "        11.7000,  8.3000, 10.2000, 10.9000, 11.0000,  9.5000, 14.5000, 14.1000,\n",
            "        16.1000, 14.3000, 11.7000, 13.4000,  9.6000,  8.7000,  8.4000, 12.8000,\n",
            "        10.5000, 17.1000, 18.4000, 15.4000, 10.8000, 11.8000, 14.9000, 12.6000,\n",
            "        14.1000, 13.0000, 13.4000, 15.2000, 16.1000, 17.8000, 14.9000, 14.1000,\n",
            "        12.7000, 13.5000, 14.9000, 20.0000, 16.4000, 17.7000, 19.5000, 20.2000,\n",
            "        21.4000, 19.9000, 19.0000, 19.1000, 19.1000, 20.1000, 19.9000, 19.6000,\n",
            "        23.2000, 29.8000, 13.8000, 13.3000, 16.7000, 12.0000, 14.6000, 21.4000,\n",
            "        23.0000, 23.7000, 25.0000, 21.8000, 20.6000, 21.2000, 19.1000, 20.6000,\n",
            "        15.2000,  7.0000,  8.1000, 13.6000, 20.1000, 21.8000, 24.5000, 23.1000,\n",
            "        19.7000, 18.3000, 21.2000, 17.5000, 16.8000, 22.4000, 20.6000, 23.9000,\n",
            "        22.0000, 11.9000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSt0D6UsVxX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f8c3a5-65f2-4052-8c51-048fcb1fab59"
      },
      "source": [
        "# Shape of inputs and targets\n",
        "print(f\"Shape of inputs is {inputs.shape}\")\n",
        "print(f\"Shape of labels is {targets.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of inputs is torch.Size([506, 13])\n",
            "Shape of labels is torch.Size([506])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xaAaLIywSVh"
      },
      "source": [
        "###**Dataset and DataLoader**\n",
        "\n",
        "We'll create a `TensorDataset`, which allows access to rows from `inputs` and `targets` as tuples, and provides standard APIs for working with many different types of datasets in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoOb0O5pweYk",
        "outputId": "c707e63c-b0e9-439c-8248-97d54471058a"
      },
      "source": [
        "# Define Dataset\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "train_ds[0:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
              "          6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
              "          4.9800e+00],\n",
              "         [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 6.4210e+00,\n",
              "          7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9690e+02,\n",
              "          9.1400e+00],\n",
              "         [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01, 7.1850e+00,\n",
              "          6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02, 1.7800e+01, 3.9283e+02,\n",
              "          4.0300e+00]]), tensor([24.0000, 21.6000, 34.7000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpO9Md-3xKGr"
      },
      "source": [
        "The `TensorDataset` allows us to access a small section of the training data using the array indexing notation (`[0:3]` in the above code). It returns a tuple with two elements. The first element contains the input variables for the selected rows, and the second contains the targets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3GRnoEOxLcL"
      },
      "source": [
        "We'll also create a `DataLoader`, which can split the data into batches of a predefined size while training. It also provides other utilities like shuffling and random sampling of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942VQWo5xttx"
      },
      "source": [
        "# Define the Dataloader\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYIVfMVlyH8K"
      },
      "source": [
        "We can use the loader in a `for` loop. In each iteration, the data loader returns one batch of data with the given batch size. If `shuffle` is set to `True`, it shuffles the training data before creating batches. Shuffling helps randomize the input to the optimization algorithm, leading to a faster reduction in the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWDFG_aNyShF",
        "outputId": "21062f56-ace1-444d-faac-c9866c8c6122"
      },
      "source": [
        "# Here we are printing one batch of data\n",
        "for inp, tgt in train_dl:\n",
        "  print(inp)\n",
        "  print(tgt)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6.2739e-01, 0.0000e+00, 8.1400e+00, 0.0000e+00, 5.3800e-01, 5.8340e+00,\n",
            "         5.6500e+01, 4.4986e+00, 4.0000e+00, 3.0700e+02, 2.1000e+01, 3.9562e+02,\n",
            "         8.4700e+00],\n",
            "        [1.4932e-01, 2.5000e+01, 5.1300e+00, 0.0000e+00, 4.5300e-01, 5.7410e+00,\n",
            "         6.6200e+01, 7.2254e+00, 8.0000e+00, 2.8400e+02, 1.9700e+01, 3.9511e+02,\n",
            "         1.3150e+01],\n",
            "        [1.3428e+00, 0.0000e+00, 1.9580e+01, 0.0000e+00, 6.0500e-01, 6.0660e+00,\n",
            "         1.0000e+02, 1.7573e+00, 5.0000e+00, 4.0300e+02, 1.4700e+01, 3.5389e+02,\n",
            "         6.4300e+00],\n",
            "        [9.2323e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.3100e-01, 6.2160e+00,\n",
            "         1.0000e+02, 1.1691e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.6615e+02,\n",
            "         9.5300e+00],\n",
            "        [2.0746e-01, 0.0000e+00, 2.7740e+01, 0.0000e+00, 6.0900e-01, 5.0930e+00,\n",
            "         9.8000e+01, 1.8226e+00, 4.0000e+00, 7.1100e+02, 2.0100e+01, 3.1843e+02,\n",
            "         2.9680e+01],\n",
            "        [1.4455e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01, 6.1720e+00,\n",
            "         9.6100e+01, 5.9505e+00, 5.0000e+00, 3.1100e+02, 1.5200e+01, 3.9690e+02,\n",
            "         1.9150e+01],\n",
            "        [2.5941e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.7900e-01, 5.3040e+00,\n",
            "         8.9100e+01, 1.6475e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 1.2736e+02,\n",
            "         2.6640e+01],\n",
            "        [6.2356e-01, 0.0000e+00, 6.2000e+00, 1.0000e+00, 5.0700e-01, 6.8790e+00,\n",
            "         7.7700e+01, 3.2721e+00, 8.0000e+00, 3.0700e+02, 1.7400e+01, 3.9039e+02,\n",
            "         9.9300e+00],\n",
            "        [9.7242e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.4000e-01, 6.4060e+00,\n",
            "         9.7200e+01, 2.0651e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.8596e+02,\n",
            "         1.9520e+01],\n",
            "        [9.6040e-02, 4.0000e+01, 6.4100e+00, 0.0000e+00, 4.4700e-01, 6.8540e+00,\n",
            "         4.2800e+01, 4.2673e+00, 4.0000e+00, 2.5400e+02, 1.7600e+01, 3.9690e+02,\n",
            "         2.9800e+00],\n",
            "        [1.8003e+00, 0.0000e+00, 1.9580e+01, 0.0000e+00, 6.0500e-01, 5.8770e+00,\n",
            "         7.9200e+01, 2.4259e+00, 5.0000e+00, 4.0300e+02, 1.4700e+01, 2.2761e+02,\n",
            "         1.2140e+01],\n",
            "        [1.6760e-01, 0.0000e+00, 7.3800e+00, 0.0000e+00, 4.9300e-01, 6.4260e+00,\n",
            "         5.2300e+01, 4.5404e+00, 5.0000e+00, 2.8700e+02, 1.9600e+01, 3.9690e+02,\n",
            "         7.2000e+00],\n",
            "        [3.9320e-02, 0.0000e+00, 3.4100e+00, 0.0000e+00, 4.8900e-01, 6.4050e+00,\n",
            "         7.3900e+01, 3.0921e+00, 2.0000e+00, 2.7000e+02, 1.7800e+01, 3.9355e+02,\n",
            "         8.2000e+00],\n",
            "        [8.0558e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.8400e-01, 5.4270e+00,\n",
            "         9.5400e+01, 2.4298e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.5258e+02,\n",
            "         1.8140e+01],\n",
            "        [5.6600e-02, 0.0000e+00, 3.4100e+00, 0.0000e+00, 4.8900e-01, 7.0070e+00,\n",
            "         8.6300e+01, 3.4217e+00, 2.0000e+00, 2.7000e+02, 1.7800e+01, 3.9690e+02,\n",
            "         5.5000e+00],\n",
            "        [1.6128e+00, 0.0000e+00, 8.1400e+00, 0.0000e+00, 5.3800e-01, 6.0960e+00,\n",
            "         9.6900e+01, 3.7598e+00, 4.0000e+00, 3.0700e+02, 2.1000e+01, 2.4831e+02,\n",
            "         2.0340e+01],\n",
            "        [3.4450e-02, 8.2500e+01, 2.0300e+00, 0.0000e+00, 4.1500e-01, 6.1620e+00,\n",
            "         3.8400e+01, 6.2700e+00, 2.0000e+00, 3.4800e+02, 1.4700e+01, 3.9377e+02,\n",
            "         7.4300e+00],\n",
            "        [3.7662e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 6.7900e-01, 6.2020e+00,\n",
            "         7.8700e+01, 1.8629e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 1.8820e+01,\n",
            "         1.4520e+01],\n",
            "        [3.6737e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.8300e-01, 6.3120e+00,\n",
            "         5.1900e+01, 3.9917e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.8862e+02,\n",
            "         1.0580e+01],\n",
            "        [1.2802e+01, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.4000e-01, 5.8540e+00,\n",
            "         9.6600e+01, 1.8956e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 2.4052e+02,\n",
            "         2.3790e+01],\n",
            "        [1.4963e+00, 0.0000e+00, 1.9580e+01, 0.0000e+00, 8.7100e-01, 5.4040e+00,\n",
            "         1.0000e+02, 1.5916e+00, 5.0000e+00, 4.0300e+02, 1.4700e+01, 3.4160e+02,\n",
            "         1.3280e+01],\n",
            "        [5.7890e-02, 1.2500e+01, 6.0700e+00, 0.0000e+00, 4.0900e-01, 5.8780e+00,\n",
            "         2.1400e+01, 6.4980e+00, 4.0000e+00, 3.4500e+02, 1.8900e+01, 3.9621e+02,\n",
            "         8.1000e+00],\n",
            "        [5.6664e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.4000e-01, 6.2190e+00,\n",
            "         1.0000e+02, 2.0048e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9569e+02,\n",
            "         1.6590e+01],\n",
            "        [4.4223e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.8400e-01, 6.0030e+00,\n",
            "         9.4500e+01, 2.5403e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.3129e+02,\n",
            "         2.1320e+01],\n",
            "        [8.1870e-02, 0.0000e+00, 2.8900e+00, 0.0000e+00, 4.4500e-01, 7.8200e+00,\n",
            "         3.6900e+01, 3.4952e+00, 2.0000e+00, 2.7600e+02, 1.8000e+01, 3.9353e+02,\n",
            "         3.5700e+00],\n",
            "        [6.7177e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.1300e-01, 6.7490e+00,\n",
            "         9.2600e+01, 2.3236e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.2000e-01,\n",
            "         1.7440e+01],\n",
            "        [9.5136e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.1300e-01, 6.7280e+00,\n",
            "         9.4100e+01, 2.4961e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 6.6800e+00,\n",
            "         1.8710e+01],\n",
            "        [2.0550e-02, 8.5000e+01, 7.4000e-01, 0.0000e+00, 4.1000e-01, 6.3830e+00,\n",
            "         3.5700e+01, 9.1876e+00, 2.0000e+00, 3.1300e+02, 1.7300e+01, 3.9690e+02,\n",
            "         5.7700e+00],\n",
            "        [9.3906e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 7.4000e-01, 5.6270e+00,\n",
            "         9.3900e+01, 1.8172e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9690e+02,\n",
            "         2.2880e+01],\n",
            "        [3.8497e+00, 0.0000e+00, 1.8100e+01, 1.0000e+00, 7.7000e-01, 6.3950e+00,\n",
            "         9.1000e+01, 2.5052e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9134e+02,\n",
            "         1.3270e+01],\n",
            "        [1.7171e-01, 2.5000e+01, 5.1300e+00, 0.0000e+00, 4.5300e-01, 5.9660e+00,\n",
            "         9.3400e+01, 6.8185e+00, 8.0000e+00, 2.8400e+02, 1.9700e+01, 3.7808e+02,\n",
            "         1.4440e+01],\n",
            "        [5.7082e+00, 0.0000e+00, 1.8100e+01, 0.0000e+00, 5.3200e-01, 6.7500e+00,\n",
            "         7.4900e+01, 3.3317e+00, 2.4000e+01, 6.6600e+02, 2.0200e+01, 3.9307e+02,\n",
            "         7.7400e+00]])\n",
            "tensor([19.9000, 18.7000, 24.3000, 50.0000,  8.1000, 27.1000, 10.4000, 27.5000,\n",
            "        17.1000, 32.0000, 23.8000, 23.8000, 22.0000, 13.8000, 23.6000, 13.5000,\n",
            "        24.1000, 10.9000, 21.2000, 10.8000, 19.6000, 22.0000, 18.4000, 19.1000,\n",
            "        43.8000, 13.4000, 14.9000, 24.7000, 12.8000, 21.7000, 16.0000, 23.7000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TRn1J7PyqPH"
      },
      "source": [
        "###**Creating a Linear Model**\n",
        "\n",
        "Instead of initializing the weights & biases manually, we can define the model using the `nn.Linear` class from PyTorch, which does it automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otW63mgryyJB",
        "outputId": "ba5db426-8e81-45a2-ef23-4f6b0f2741d5"
      },
      "source": [
        "# Define the model\n",
        "model = torch.nn.Linear(13, 1)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2189,  0.2017, -0.1480,  0.2069,  0.0198,  0.0188,  0.0324, -0.1464,\n",
            "          0.2042, -0.1922,  0.0617,  0.1403,  0.0756]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0802], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq-UyxYgzUIg",
        "outputId": "4bde9e78-664d-4287-cb12-c9e97ce019ac"
      },
      "source": [
        "# Parameters\n",
        "list(model.parameters()) # Returns a list containing all the weights and bias matrices present in the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.2189,  0.2017, -0.1480,  0.2069,  0.0198,  0.0188,  0.0324, -0.1464,\n",
              "           0.2042, -0.1922,  0.0617,  0.1403,  0.0756]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.0802], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LILLcsnznsf",
        "outputId": "a08f5819-45f7-4504-9680-5c1796ec1b22"
      },
      "source": [
        "# Generate predictions\n",
        "preds = model(inputs)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.3482e+00],\n",
              "        [ 1.2379e+01],\n",
              "        [ 1.0860e+01],\n",
              "        [ 1.5199e+01],\n",
              "        [ 1.5981e+01],\n",
              "        [ 1.5705e+01],\n",
              "        [ 1.5621e+00],\n",
              "        [ 3.1651e+00],\n",
              "        [ 2.6501e+00],\n",
              "        [ 1.1588e+00],\n",
              "        [ 2.5540e+00],\n",
              "        [ 2.2442e+00],\n",
              "        [ 2.1634e-01],\n",
              "        [-1.2190e-01],\n",
              "        [-1.5643e+00],\n",
              "        [-4.2921e-01],\n",
              "        [-2.5874e+00],\n",
              "        [-3.1739e-01],\n",
              "        [-1.5657e+01],\n",
              "        [-3.2917e-01],\n",
              "        [-5.7346e-01],\n",
              "        [ 7.2315e-01],\n",
              "        [ 1.8786e+00],\n",
              "        [ 1.8267e+00],\n",
              "        [ 1.2412e+00],\n",
              "        [-1.1765e+01],\n",
              "        [-1.5035e+00],\n",
              "        [-1.1157e+01],\n",
              "        [ 9.7414e-02],\n",
              "        [-1.1909e+00],\n",
              "        [-2.9721e+00],\n",
              "        [-1.1158e+00],\n",
              "        [-2.0781e+01],\n",
              "        [-3.3910e+00],\n",
              "        [-1.8566e+01],\n",
              "        [ 6.0614e+00],\n",
              "        [ 3.2614e+00],\n",
              "        [ 5.0466e+00],\n",
              "        [ 4.3326e+00],\n",
              "        [ 2.3976e+01],\n",
              "        [ 2.3613e+01],\n",
              "        [ 9.8640e+00],\n",
              "        [ 9.7625e+00],\n",
              "        [ 1.1443e+01],\n",
              "        [ 1.1965e+01],\n",
              "        [ 1.2962e+01],\n",
              "        [ 1.3249e+01],\n",
              "        [ 1.4633e+01],\n",
              "        [ 1.6409e+01],\n",
              "        [ 1.4191e+01],\n",
              "        [ 1.5777e+01],\n",
              "        [ 1.5803e+01],\n",
              "        [ 1.4554e+01],\n",
              "        [ 1.4792e+01],\n",
              "        [-1.6200e+01],\n",
              "        [ 3.2245e+01],\n",
              "        [ 1.4508e+01],\n",
              "        [ 2.8468e+01],\n",
              "        [ 7.9313e+00],\n",
              "        [ 9.6788e+00],\n",
              "        [ 1.0303e+01],\n",
              "        [ 8.9597e+00],\n",
              "        [ 1.0126e+01],\n",
              "        [ 9.2590e+00],\n",
              "        [ 2.0163e+01],\n",
              "        [ 8.5495e+00],\n",
              "        [ 9.3930e+00],\n",
              "        [-6.5340e+00],\n",
              "        [-5.5501e+00],\n",
              "        [-5.9942e+00],\n",
              "        [-4.1912e+00],\n",
              "        [-4.5456e+00],\n",
              "        [-3.2415e+00],\n",
              "        [-5.0424e+00],\n",
              "        [-2.0486e+01],\n",
              "        [-2.0734e+01],\n",
              "        [-2.0826e+01],\n",
              "        [-2.0028e+01],\n",
              "        [-1.9835e+01],\n",
              "        [-1.9203e+01],\n",
              "        [ 8.9200e+00],\n",
              "        [ 1.0080e+01],\n",
              "        [ 8.9770e+00],\n",
              "        [ 8.6247e+00],\n",
              "        [ 1.1115e+01],\n",
              "        [ 1.0555e+01],\n",
              "        [ 1.1183e+01],\n",
              "        [ 1.1216e+01],\n",
              "        [ 7.7483e+00],\n",
              "        [ 6.8965e+00],\n",
              "        [ 6.7176e+00],\n",
              "        [ 7.1142e+00],\n",
              "        [ 1.0934e+01],\n",
              "        [ 1.0166e+01],\n",
              "        [ 1.2154e+01],\n",
              "        [ 3.8384e-01],\n",
              "        [ 5.8595e+00],\n",
              "        [ 6.2762e+00],\n",
              "        [ 4.4767e+00],\n",
              "        [ 5.9654e+00],\n",
              "        [-1.4218e+01],\n",
              "        [-1.4532e+01],\n",
              "        [-5.9384e+01],\n",
              "        [-1.3701e+01],\n",
              "        [-1.3922e+01],\n",
              "        [-1.3163e+01],\n",
              "        [-1.2933e+01],\n",
              "        [-1.4605e+01],\n",
              "        [-1.3338e+01],\n",
              "        [-1.3835e+01],\n",
              "        [-1.4970e+01],\n",
              "        [-2.3412e+01],\n",
              "        [-2.2642e+01],\n",
              "        [-2.2224e+01],\n",
              "        [-2.4205e+01],\n",
              "        [-2.9854e+01],\n",
              "        [-2.3897e+01],\n",
              "        [-2.3533e+01],\n",
              "        [-3.1266e+01],\n",
              "        [-2.4277e+01],\n",
              "        [ 1.9494e+01],\n",
              "        [ 1.8354e+01],\n",
              "        [ 1.8994e+01],\n",
              "        [ 1.8632e+01],\n",
              "        [ 1.9254e+01],\n",
              "        [ 1.9616e+01],\n",
              "        [ 1.7255e+01],\n",
              "        [-2.5674e+01],\n",
              "        [-2.5022e+01],\n",
              "        [-2.4850e+01],\n",
              "        [-2.5532e+01],\n",
              "        [-2.5174e+01],\n",
              "        [-2.6956e+01],\n",
              "        [-2.6418e+01],\n",
              "        [-4.3660e+01],\n",
              "        [-2.5230e+01],\n",
              "        [-2.7729e+01],\n",
              "        [-2.5490e+01],\n",
              "        [-2.5282e+01],\n",
              "        [-2.4756e+01],\n",
              "        [-2.5748e+01],\n",
              "        [-2.3233e+01],\n",
              "        [-1.6521e+01],\n",
              "        [-1.6600e+01],\n",
              "        [-1.6744e+01],\n",
              "        [-4.8289e+01],\n",
              "        [-4.9715e+01],\n",
              "        [-1.7628e+01],\n",
              "        [-2.2666e+01],\n",
              "        [-2.3774e+01],\n",
              "        [-2.1552e+01],\n",
              "        [-2.5949e+01],\n",
              "        [-2.6074e+01],\n",
              "        [-3.6840e+01],\n",
              "        [-2.8648e+01],\n",
              "        [-6.1318e+01],\n",
              "        [-6.1238e+01],\n",
              "        [-2.3705e+01],\n",
              "        [-2.4793e+01],\n",
              "        [-2.3228e+01],\n",
              "        [-2.7014e+01],\n",
              "        [-2.2542e+01],\n",
              "        [-1.9875e+01],\n",
              "        [-2.0147e+01],\n",
              "        [-1.8785e+01],\n",
              "        [-4.0452e+01],\n",
              "        [-2.2821e+01],\n",
              "        [-4.2755e+01],\n",
              "        [-3.2372e+01],\n",
              "        [-2.7751e+01],\n",
              "        [-3.3138e+01],\n",
              "        [-2.5149e+01],\n",
              "        [ 4.0740e+00],\n",
              "        [ 3.3064e+00],\n",
              "        [ 2.5147e+00],\n",
              "        [ 6.6461e-01],\n",
              "        [ 1.7296e+00],\n",
              "        [ 2.6580e+00],\n",
              "        [ 2.2022e+00],\n",
              "        [ 2.2039e+01],\n",
              "        [ 2.2877e+01],\n",
              "        [ 2.2516e+01],\n",
              "        [ 2.2755e+01],\n",
              "        [ 2.3290e+01],\n",
              "        [ 2.2859e+01],\n",
              "        [ 2.1534e+01],\n",
              "        [ 2.1201e+01],\n",
              "        [-9.1791e+00],\n",
              "        [-1.1383e+01],\n",
              "        [-9.0279e+00],\n",
              "        [-1.2593e+01],\n",
              "        [-1.0643e+01],\n",
              "        [-1.0805e+01],\n",
              "        [ 1.7114e+01],\n",
              "        [ 1.5009e+01],\n",
              "        [ 2.4756e+01],\n",
              "        [ 1.0137e+01],\n",
              "        [ 4.5820e+00],\n",
              "        [ 9.8043e+00],\n",
              "        [-1.0137e+00],\n",
              "        [-2.8353e+00],\n",
              "        [ 7.1268e+00],\n",
              "        [ 6.3162e+00],\n",
              "        [ 3.3408e+01],\n",
              "        [ 3.2983e+01],\n",
              "        [ 4.0532e+00],\n",
              "        [ 4.7217e+00],\n",
              "        [ 5.1425e+00],\n",
              "        [ 3.5112e+00],\n",
              "        [ 7.7631e+00],\n",
              "        [ 6.5097e+00],\n",
              "        [ 7.2474e+00],\n",
              "        [ 4.8919e+00],\n",
              "        [ 2.7181e+00],\n",
              "        [-1.5935e+00],\n",
              "        [ 4.1579e+00],\n",
              "        [ 4.8503e+00],\n",
              "        [ 5.2678e+00],\n",
              "        [ 7.0299e+00],\n",
              "        [ 5.9198e+00],\n",
              "        [ 1.4398e+00],\n",
              "        [ 2.8839e+00],\n",
              "        [ 9.1988e-01],\n",
              "        [ 1.5438e+00],\n",
              "        [-4.4056e-01],\n",
              "        [-6.2447e-01],\n",
              "        [ 3.8687e-02],\n",
              "        [-2.0874e+00],\n",
              "        [-3.5836e+00],\n",
              "        [-3.0461e+00],\n",
              "        [-1.2514e+00],\n",
              "        [-1.7497e+00],\n",
              "        [-6.8779e-01],\n",
              "        [-1.6741e+00],\n",
              "        [-3.9176e+00],\n",
              "        [-1.7879e+00],\n",
              "        [ 4.2392e-01],\n",
              "        [-6.5929e-02],\n",
              "        [ 3.5575e+00],\n",
              "        [ 5.0184e+00],\n",
              "        [ 6.7497e+00],\n",
              "        [ 7.6324e+00],\n",
              "        [ 3.9817e+00],\n",
              "        [ 2.3478e+00],\n",
              "        [-2.4783e+00],\n",
              "        [ 1.0009e-01],\n",
              "        [-1.5703e+00],\n",
              "        [-2.0613e+00],\n",
              "        [-3.2531e+00],\n",
              "        [-1.8179e+00],\n",
              "        [-1.6094e+00],\n",
              "        [-4.5969e+00],\n",
              "        [-3.6439e+00],\n",
              "        [-1.9873e+00],\n",
              "        [ 1.1801e+01],\n",
              "        [ 1.1900e+01],\n",
              "        [ 2.7153e+01],\n",
              "        [ 1.2542e+01],\n",
              "        [ 1.2241e+01],\n",
              "        [ 1.3358e+01],\n",
              "        [ 1.3061e+01],\n",
              "        [ 1.2510e+01],\n",
              "        [ 1.2255e+01],\n",
              "        [ 1.3754e+01],\n",
              "        [ 1.2605e+01],\n",
              "        [ 1.2491e+01],\n",
              "        [ 1.2367e+01],\n",
              "        [ 1.1243e+01],\n",
              "        [ 1.1172e+01],\n",
              "        [ 1.9696e+01],\n",
              "        [ 1.8404e+01],\n",
              "        [ 1.8220e+01],\n",
              "        [ 1.9476e+01],\n",
              "        [ 1.8764e+01],\n",
              "        [ 1.7070e+01],\n",
              "        [ 1.7125e+01],\n",
              "        [ 1.6624e+01],\n",
              "        [ 1.6350e+01],\n",
              "        [ 1.7105e+01],\n",
              "        [ 2.0734e+01],\n",
              "        [ 2.0245e+01],\n",
              "        [ 2.0019e+01],\n",
              "        [ 1.8406e+01],\n",
              "        [ 3.7088e+01],\n",
              "        [ 1.9895e+01],\n",
              "        [ 1.0437e+01],\n",
              "        [ 1.9693e+01],\n",
              "        [ 1.2129e+01],\n",
              "        [ 1.2630e+01],\n",
              "        [ 8.5111e+00],\n",
              "        [ 2.6641e+01],\n",
              "        [ 2.6667e+01],\n",
              "        [ 2.6595e+01],\n",
              "        [ 5.5840e-01],\n",
              "        [ 1.4669e+00],\n",
              "        [ 7.4831e-01],\n",
              "        [ 8.8958e-01],\n",
              "        [ 2.2751e+00],\n",
              "        [-1.3064e+00],\n",
              "        [-1.1708e+00],\n",
              "        [ 2.8394e+00],\n",
              "        [ 2.1257e+00],\n",
              "        [-3.4150e-01],\n",
              "        [ 3.1563e-01],\n",
              "        [ 2.2977e+01],\n",
              "        [ 2.3717e+01],\n",
              "        [ 2.4533e+01],\n",
              "        [ 2.4533e+01],\n",
              "        [ 6.0898e-01],\n",
              "        [ 7.2665e-01],\n",
              "        [-6.1882e+00],\n",
              "        [-8.8548e-02],\n",
              "        [ 1.3317e+00],\n",
              "        [ 3.3223e-01],\n",
              "        [ 8.8265e-01],\n",
              "        [ 7.5053e-01],\n",
              "        [ 6.5230e-01],\n",
              "        [ 9.4622e-01],\n",
              "        [ 2.6049e-01],\n",
              "        [ 2.5323e-01],\n",
              "        [ 3.4957e+00],\n",
              "        [ 3.5376e+00],\n",
              "        [ 3.4623e+00],\n",
              "        [ 3.7265e+00],\n",
              "        [ 3.0307e+00],\n",
              "        [ 1.5443e+00],\n",
              "        [ 2.5586e+00],\n",
              "        [ 3.5213e+00],\n",
              "        [-2.6551e+01],\n",
              "        [-2.8034e+01],\n",
              "        [-2.8453e+01],\n",
              "        [ 5.3688e+00],\n",
              "        [ 4.0109e-01],\n",
              "        [ 1.4072e+01],\n",
              "        [ 1.4119e+01],\n",
              "        [ 1.5202e+01],\n",
              "        [ 1.5825e+01],\n",
              "        [ 1.5963e+01],\n",
              "        [ 1.5395e+01],\n",
              "        [ 1.5860e+01],\n",
              "        [ 1.6251e+01],\n",
              "        [ 1.0013e+01],\n",
              "        [-2.3586e+01],\n",
              "        [-1.0230e+00],\n",
              "        [-3.4888e+00],\n",
              "        [-1.1009e+01],\n",
              "        [-1.3671e+01],\n",
              "        [ 6.4033e+00],\n",
              "        [ 1.9157e+01],\n",
              "        [ 1.2589e-01],\n",
              "        [ 1.4410e+00],\n",
              "        [-1.2922e+01],\n",
              "        [-1.0302e+01],\n",
              "        [ 3.7881e+01],\n",
              "        [ 7.5238e+00],\n",
              "        [ 6.3293e+00],\n",
              "        [-6.4957e+01],\n",
              "        [-6.4758e+01],\n",
              "        [-6.4306e+01],\n",
              "        [-6.5324e+01],\n",
              "        [-6.7681e+01],\n",
              "        [-7.0576e+01],\n",
              "        [-6.6508e+01],\n",
              "        [-6.9935e+01],\n",
              "        [-7.0736e+01],\n",
              "        [-7.0440e+01],\n",
              "        [-7.5415e+01],\n",
              "        [-9.8927e+01],\n",
              "        [-6.7278e+01],\n",
              "        [-6.6969e+01],\n",
              "        [-6.4439e+01],\n",
              "        [-6.7123e+01],\n",
              "        [-7.0077e+01],\n",
              "        [-6.0515e+01],\n",
              "        [-5.8665e+01],\n",
              "        [-6.0310e+01],\n",
              "        [-6.5434e+01],\n",
              "        [-6.1849e+01],\n",
              "        [-5.8734e+01],\n",
              "        [-6.0467e+01],\n",
              "        [-4.5056e+01],\n",
              "        [-6.0555e+01],\n",
              "        [-6.1827e+01],\n",
              "        [-6.2009e+01],\n",
              "        [-7.4781e+01],\n",
              "        [-5.9657e+01],\n",
              "        [-5.8144e+01],\n",
              "        [-5.8598e+01],\n",
              "        [-6.3548e+01],\n",
              "        [-6.2321e+01],\n",
              "        [-6.3295e+01],\n",
              "        [-6.6286e+01],\n",
              "        [-6.1280e+01],\n",
              "        [-6.2841e+01],\n",
              "        [-6.1656e+01],\n",
              "        [-6.3152e+01],\n",
              "        [-6.2999e+01],\n",
              "        [-6.3009e+01],\n",
              "        [-5.4903e+01],\n",
              "        [-7.0129e+01],\n",
              "        [-5.8109e+01],\n",
              "        [-6.0953e+01],\n",
              "        [-6.4895e+01],\n",
              "        [-5.8849e+01],\n",
              "        [-6.4401e+01],\n",
              "        [-5.0666e+01],\n",
              "        [-6.3035e+01],\n",
              "        [-7.1139e+01],\n",
              "        [-7.3598e+01],\n",
              "        [-9.1450e+01],\n",
              "        [-1.0896e+02],\n",
              "        [-1.1169e+02],\n",
              "        [-1.1057e+02],\n",
              "        [-8.3930e+01],\n",
              "        [-9.6149e+01],\n",
              "        [-1.1136e+02],\n",
              "        [-1.1427e+02],\n",
              "        [-9.6117e+01],\n",
              "        [-1.0137e+02],\n",
              "        [-1.1098e+02],\n",
              "        [-7.3049e+01],\n",
              "        [-7.3876e+01],\n",
              "        [-7.7156e+01],\n",
              "        [-1.1819e+02],\n",
              "        [-1.1860e+02],\n",
              "        [-1.1511e+02],\n",
              "        [-1.1535e+02],\n",
              "        [-1.1005e+02],\n",
              "        [-1.0525e+02],\n",
              "        [-1.0911e+02],\n",
              "        [-1.0692e+02],\n",
              "        [-1.0645e+02],\n",
              "        [-1.0614e+02],\n",
              "        [-1.0529e+02],\n",
              "        [-1.0324e+02],\n",
              "        [-1.0193e+02],\n",
              "        [-1.1319e+02],\n",
              "        [-1.1472e+02],\n",
              "        [-1.0649e+02],\n",
              "        [-6.2066e+01],\n",
              "        [-6.0170e+01],\n",
              "        [-6.3697e+01],\n",
              "        [-6.3345e+01],\n",
              "        [-6.3482e+01],\n",
              "        [-8.3113e+01],\n",
              "        [-1.1133e+02],\n",
              "        [-7.4142e+01],\n",
              "        [-6.3568e+01],\n",
              "        [-6.2338e+01],\n",
              "        [-7.5647e+01],\n",
              "        [-1.1880e+02],\n",
              "        [-6.9079e+01],\n",
              "        [-6.5225e+01],\n",
              "        [-6.5617e+01],\n",
              "        [-1.1718e+02],\n",
              "        [-1.1230e+02],\n",
              "        [-1.1791e+02],\n",
              "        [-1.1855e+02],\n",
              "        [-8.0882e+01],\n",
              "        [-6.3682e+01],\n",
              "        [-8.3656e+01],\n",
              "        [-6.4977e+01],\n",
              "        [-6.3811e+01],\n",
              "        [-6.4489e+01],\n",
              "        [-6.4216e+01],\n",
              "        [-7.4521e+01],\n",
              "        [-1.1678e+02],\n",
              "        [-7.2560e+01],\n",
              "        [-6.5921e+01],\n",
              "        [-6.3226e+01],\n",
              "        [-6.4159e+01],\n",
              "        [-6.4499e+01],\n",
              "        [-6.5237e+01],\n",
              "        [-6.8003e+01],\n",
              "        [-6.8983e+01],\n",
              "        [-7.5776e+01],\n",
              "        [-6.3537e+01],\n",
              "        [-6.7273e+01],\n",
              "        [-6.4615e+01],\n",
              "        [-6.3830e+01],\n",
              "        [-6.4937e+01],\n",
              "        [-6.5373e+01],\n",
              "        [-6.5051e+01],\n",
              "        [-6.7075e+01],\n",
              "        [-6.9954e+01],\n",
              "        [-6.7076e+01],\n",
              "        [-6.4768e+01],\n",
              "        [-6.6655e+01],\n",
              "        [-7.8917e+01],\n",
              "        [-8.5435e+01],\n",
              "        [-8.8619e+01],\n",
              "        [-7.9425e+01],\n",
              "        [-7.9358e+01],\n",
              "        [-1.5928e+01],\n",
              "        [-1.6150e+01],\n",
              "        [-1.6888e+01],\n",
              "        [-1.4668e+01],\n",
              "        [-1.5285e+01],\n",
              "        [-1.5477e+01],\n",
              "        [-1.5226e+01],\n",
              "        [-1.4921e+01],\n",
              "        [ 5.1070e+00],\n",
              "        [ 6.0125e+00],\n",
              "        [ 6.2523e+00],\n",
              "        [ 5.7515e+00],\n",
              "        [ 6.0214e+00]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rAh40W1z1uc"
      },
      "source": [
        "###**Loss Function**\n",
        "\n",
        "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1n1kaIMz66f",
        "outputId": "291a412f-af01-468d-897f-b10d117f7dd4"
      },
      "source": [
        "# Define the loss function and compute the loss\n",
        "loss_fn = F.mse_loss\n",
        "loss = loss_fn(preds, targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3464.1326, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Using a target size (torch.Size([506])) that is different to the input size (torch.Size([506, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwfAJdEI0XWK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPZO0RUC0Xqd"
      },
      "source": [
        "###**Optimizer**\n",
        "\n",
        "Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer `optim.SGD`. SGD is short for \"Stochastic Gradient Descent\". The term _stochastic_ indicates that samples are selected in random batches instead of as a single group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPnFwfWs0h6P",
        "outputId": "69c5317d-bcba-4732-b103-4312e22a3be3"
      },
      "source": [
        "# Define Optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
        "print(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 1e-05\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd7icacUVZB0",
        "outputId": "9913bc63-75c9-4e95-f079-ee80a9f85ca6"
      },
      "source": [
        "#1. Geenrate Predictions\n",
        "preds = model(inputs)\n",
        "\n",
        "# 2. Calculate loss\n",
        "loss = loss_fn(preds, targets)\n",
        "\n",
        "# 3. Compute gradients\n",
        "loss.backward()\n",
        "\n",
        "# 4. Update parameters using gradients\n",
        "opt.step()\n",
        "\n",
        "# 5. Reset the gradients to zero\n",
        "opt.zero_grad()\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(nan, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Using a target size (torch.Size([506])) that is different to the input size (torch.Size([506, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E184_fuO0s0P"
      },
      "source": [
        "Note that `model.parameters()` is passed as an argument to `optim.SGD` so that the optimizer knows which matrices should be modified during the update step. Also, we can specify a learning rate that controls the amount by which the parameters are modified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GuR8poy0utm"
      },
      "source": [
        "###**Train the model**\n",
        "\n",
        "We are now ready to train the model. We'll follow the same process to implement gradient descent:\n",
        "\n",
        "1. Generate predictions\n",
        "\n",
        "2. Calculate the loss\n",
        "\n",
        "3. Compute gradients w.r.t the weights and biases\n",
        "\n",
        "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "\n",
        "5. Reset the gradients to zero\n",
        "\n",
        "The only change is that we'll work batches of data instead of processing the entire training data in every iteration. Let's define a utility function `fit` that trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nyKIWfo0zTG"
      },
      "source": [
        "# Utility Function to train the model\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "  # Repeat for given number of epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # Train with batces of data\n",
        "    for inp, tgt in train_dl:\n",
        "      # 1. Geenrate Predictions\n",
        "      preds = model(inp)\n",
        "\n",
        "      # 2. Calculate loss\n",
        "      loss = loss_fn(preds, tgt)\n",
        "\n",
        "      # 3. Compute gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # 4. Update parameters using gradients\n",
        "      opt.step()\n",
        "\n",
        "      # 5. Reset the gradients to zero\n",
        "      opt.zero_grad()\n",
        "\n",
        "    # Print the progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {round(loss.item(), 4)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuQ7ZKwO1-8-"
      },
      "source": [
        "Some things to note above:\n",
        "\n",
        "* We use the data loader defined earlier to get batches of data for every iteration.\n",
        "\n",
        "* Instead of updating parameters (weights and biases) manually, we use `opt.step` to perform the update and `opt.zero_grad` to reset the gradients to zero.\n",
        "\n",
        "* We've also added a log statement that prints the loss from the last batch of data for every 10th epoch to track training progress. `loss.item` returns the actual value stored in the loss tensor.\n",
        "\n",
        "Let's train the model for 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DROXajGO2BsU",
        "outputId": "882904df-95f5-4602-d92b-295dbb9679a0"
      },
      "source": [
        "# Calling the Training function of our dataset\n",
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Using a target size (torch.Size([26])) that is different to the input size (torch.Size([26, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: nan\n",
            "Epoch [20/100], Loss: nan\n",
            "Epoch [30/100], Loss: nan\n",
            "Epoch [40/100], Loss: nan\n",
            "Epoch [50/100], Loss: nan\n",
            "Epoch [60/100], Loss: nan\n",
            "Epoch [70/100], Loss: nan\n",
            "Epoch [80/100], Loss: nan\n",
            "Epoch [90/100], Loss: nan\n",
            "Epoch [100/100], Loss: nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFxAH3TC2s60",
        "outputId": "e9d99241-34fb-48a8-e72d-fdcf554e0ccd"
      },
      "source": [
        "# Testing for one input\n",
        "model(torch.tensor([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01, 6.5750e+00,\n",
        "        6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02, 1.5300e+01, 3.9690e+02,\n",
        "        4.9800e+00]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[nan]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}